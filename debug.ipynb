{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-08T10:01:21.417850Z",
     "start_time": "2025-07-08T10:01:18.808214Z"
    }
   },
   "outputs": [],
   "source": [
    "from assets.CustomTransformer import TransformerEncoderLayer,TransformerDecoderLayer\n",
    "from assets.utils import PositionalEncoding,generate_square_subsequent_mask\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "from assets.CustomTransformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train = torch.tensor([[\n",
    "    [1,3,5,7],\n",
    "    [2,4,6,8]\n",
    "],\n",
    "[\n",
    "    [9,11,13,17],\n",
    "    [10,12,14,16]\n",
    "]],dtype=torch.float32)\n",
    "\n",
    "y_train = torch.tensor([[\n",
    "    [2,6,10,14],\n",
    "    [4,8,12,16]\n",
    "],\n",
    "[\n",
    "    [18,22,26,34],\n",
    "    [20,24,28,32]\n",
    "]],dtype=torch.float32)\n",
    "\n",
    "#loader = data.DataLoader(data.TensorDataset())\n",
    "loader = data.DataLoader(data.TensorDataset(X_train,y_train),shuffle=True,batch_size=8)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-08T10:01:21.438237Z",
     "start_time": "2025-07-08T10:01:21.424272Z"
    }
   },
   "id": "75c2030702685da0",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = Transformer(src_vocab_size=4,tgt_vocab_size=4,d_model=16,n_heads=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-08T10:01:21.448763Z",
     "start_time": "2025-07-08T10:01:21.431168Z"
    }
   },
   "id": "5e565c9a194e7be0",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 1, 2, 4])\n",
      "torch.Size([1, 1, 1, 2, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc\u001B[49m\u001B[43m=\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrg\u001B[49m\u001B[43m=\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc_pad_idx\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrg_pad_idx\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/TimeSeries/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1510\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/TimeSeries/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1515\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1516\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1517\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1518\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1519\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1520\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1522\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1523\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/TimeSeries/assets/CustomTransformer.py:311\u001B[39m, in \u001B[36mTransformer.forward\u001B[39m\u001B[34m(self, src, trg, src_pad_idx, trg_pad_idx)\u001B[39m\n\u001B[32m    308\u001B[39m \u001B[38;5;28mprint\u001B[39m(trg_look_ahead_mask.shape)\n\u001B[32m    309\u001B[39m \u001B[38;5;66;03m# Combine decoder self-attention masks:\u001B[39;00m\n\u001B[32m    310\u001B[39m \u001B[38;5;66;03m# We need to mask padding AND future tokens\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m311\u001B[39m trg_mask = \u001B[43mtrg_padding_mask\u001B[49m\u001B[43m \u001B[49m\u001B[43m&\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrg_look_ahead_mask\u001B[49m\n\u001B[32m    313\u001B[39m \u001B[38;5;66;03m# Encoder forward pass\u001B[39;00m\n\u001B[32m    314\u001B[39m enc_output = \u001B[38;5;28mself\u001B[39m.encoder(src, src_mask)\n",
      "\u001B[31mRuntimeError\u001B[39m: The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 4"
     ]
    }
   ],
   "source": [
    "model( src=X_train, trg=y_train, src_pad_idx = 0, trg_pad_idx=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-08T10:01:21.946143Z",
     "start_time": "2025-07-08T10:01:21.447665Z"
    }
   },
   "id": "2a447b757479bce0",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "torch.Size([2, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(torch.randint(1, 4, (2, 4)).shape)\n",
    "print(X_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-08T09:56:39.583222Z",
     "start_time": "2025-07-08T09:56:39.574177Z"
    }
   },
   "id": "c690b98f91cc8466",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 1, 2, 4])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = X_train\n",
    "pad_idx = 0\n",
    "mask = (seq != pad_idx).unsqueeze(1)\n",
    "mask.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-08T09:55:18.395487Z",
     "start_time": "2025-07-08T09:55:18.387495Z"
    }
   },
   "id": "4d4efedad917bdba",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2, 1, 3, 1],\n        [1, 2, 3, 3]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(1, 4, (2, 4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-08T09:51:18.761598Z",
     "start_time": "2025-07-08T09:51:18.754815Z"
    }
   },
   "id": "9fc6895efb9c2a10",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 4, 4])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_ahead_mask = torch.triu(torch.ones(4, 4), diagonal=1).bool()\n",
    "look_ahead_mask.unsqueeze(0).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-08T10:01:38.971150Z",
     "start_time": "2025-07-08T10:01:38.960118Z"
    }
   },
   "id": "2de40bbd3b35fb06",
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
